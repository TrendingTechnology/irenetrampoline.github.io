---
layout: post
title: On sources of unfairness in supervised learning
comments: true
length: 8 min read
tagline: when 

categories:
- blog
---


## Fairness

Are lab focuses on fairness in healthcare, and when we think about the vast body of fairness research out there, we realize that Healthcare algorithms have numerous needs. For example most Healthcare analysis often trade-off and accuracy. This can be inconvenient at times and life-threatening in hell where any drop in accuracy can have large repercussions. Additionally we want to be able to budget resources. Healthcare in America is a trillion-dollar. If we have funds to increase fairness in healthcare algorithms, what is the best value for our money? Lastly how do we sign blame? Are all types of unfairness created equal? If we Define fairness as the difference in prediction accuracies between groups, can we attribute sources of these unfairness metrics 

Boil it down we want to fix an algorithm with a certain budget, a million dollar well what can I do? I want to emphasize hear that algorithm includes both the data that we trained validated and tested our model on, and the mathematical model itself. Both are up for grabs. We can improve the model, we can add more data, we can add more features to the existing data points we have. 

## Bias, variance, and noise

These suggestions closely aligned with bias,, and Noise the bias variance trade-off hot in introductory machine learning class, and check out this blog for a fun explanation. Pedro Dominguez has great work in 2001 to unify several notations. We can decompose the air into 3 linear terms: bias, variance, and noise. Decreasing any of them without increasing the other with only two smaller error. 

However we are concerned with the difference in errors if we Define big gamma as the difference between our two groups specific errors, we can we can decompose each error term into bias variance and Noise. Week and then rewrite big gamma as the differences between biases, frances, noises. I want to call out that if the noise values for each group are not the same, no model can be 0-disciminatory in expectation without access to additional information or increasing bias / variance wrt to the Bayes optimal classifier. 

## ICU Mortality



<meta name="twitter:card" content="summary" />
<!-- <meta name="twitter:image" content="http://irenechen.net/irene.jpg" /> -->
<meta name="twitter:site" content="@irenetrampoline" />
<meta name="twitter:title" content="MLHC 2018 Recap" />
<meta name="twitter:description" content="Over 300 clinicians and machine learning researchers met in Palo Alto for three days of tutorials, keynotes, and papers." />
<meta name="twitter:image:src" content="http://irenechen.net/assets/mlhc2018_group.jpg" />